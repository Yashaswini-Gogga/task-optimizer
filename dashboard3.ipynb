{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4504d7-6f09-4228-a242-e308bceb413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 17:56:18.281 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\anaconda\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-29 17:56:18.286 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from textblob import TextBlob\n",
    "import speech_recognition as sr\n",
    "import tempfile\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Task Suggestion Function\n",
    "def suggest_task(emotion):\n",
    "    tasks = {\n",
    "        \"happy\": \"Share your happiness with friends!\",\n",
    "        \"sad\": \"Take a short walk or talk to a friend.\",\n",
    "        \"angry\": \"Take deep breaths, drink water.\",\n",
    "        \"fear\": \"Write down what's worrying you.\",\n",
    "        \"neutral\": \"Focus on your current goals!\",\n",
    "        \"surprise\": \"Pause and reflect on the new experience.\",\n",
    "        \"disgust\": \"Step away from the situation for clarity.\"\n",
    "    }\n",
    "    return tasks.get(emotion.lower(), \"Relax and take care of yourself.\")\n",
    "\n",
    "# Text-Based Emotion Detection\n",
    "def detect_text_emotion(text):\n",
    "    analysis = TextBlob(text)\n",
    "    polarity = analysis.sentiment.polarity\n",
    "    if polarity > 0.3:\n",
    "        return \"happy\"\n",
    "    elif polarity < -0.3:\n",
    "        return \"sad\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# Audio-Based Emotion Detection (using speech to text + TextBlob)\n",
    "def detect_audio_emotion(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as tmp_wav:\n",
    "        audio = AudioSegment.from_file(audio_file)\n",
    "        audio.export(tmp_wav.name, format=\"wav\")\n",
    "\n",
    "    try:\n",
    "        with sr.AudioFile(tmp_wav.name) as source:\n",
    "            audio_data = recognizer.record(source)\n",
    "            text = recognizer.recognize_google(audio_data)\n",
    "            emotion = detect_text_emotion(text)\n",
    "            return emotion, text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Could not understand the audio.\", \"\"\n",
    "    except sr.RequestError:\n",
    "        return \"Error connecting to Google's service.\", \"\"\n",
    "    finally:\n",
    "        os.remove(tmp_wav.name)\n",
    "\n",
    "# Streamlit UI\n",
    "st.set_page_config(page_title=\"Emotion Detector & Task Suggester\", page_icon=\"ðŸ§ ðŸŽ§\", layout=\"centered\")\n",
    "st.title(\"ðŸ§ ðŸŽ§ Emotion Detection & Task Recommender\")\n",
    "\n",
    "mode = st.selectbox(\"Choose Input Type:\", [\"Text\", \"Audio\"])\n",
    "\n",
    "if mode == \"Text\":\n",
    "    user_text = st.text_area(\"Enter your thoughts:\")\n",
    "    if st.button(\"Analyze Text\"):\n",
    "        if user_text:\n",
    "            emotion = detect_text_emotion(user_text)\n",
    "            task = suggest_task(emotion)\n",
    "            st.success(f\"Detected Emotion: **{emotion}**\")\n",
    "            st.info(f\"ðŸ’¡ Suggested Task: {task}\")\n",
    "        else:\n",
    "            st.warning(\"Please enter some text.\")\n",
    "\n",
    "elif mode == \"Audio\":\n",
    "    uploaded_file = st.file_uploader(\"Upload an audio file (WAV, MP3, OGG)\", type=['wav', 'mp3', 'ogg'])\n",
    "    if st.button(\"Analyze Audio\"):\n",
    "        if uploaded_file:\n",
    "            emotion, transcript = detect_audio_emotion(uploaded_file)\n",
    "            if transcript:\n",
    "                task = suggest_task(emotion)\n",
    "                st.success(f\"Transcript: {transcript}\")\n",
    "                st.success(f\"Detected Emotion: **{emotion}**\")\n",
    "                st.info(f\"ðŸ’¡ Suggested Task: {task}\")\n",
    "            else:\n",
    "                st.error(emotion)\n",
    "        else:\n",
    "            st.warning(\"Please upload an audio file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5842e57-11e4-416f-b5c0-bea21402fcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
